{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YunJiye/project_Pzone/blob/vision/YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DxdUCxk8pME-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5235650-c0f6-49bf-c26b-ac1b7e23d94f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-pB0OhSq5U6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "108830ae-46f8-4e99-8bc8-42cc199d323f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14378, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 14378 (delta 1), reused 4 (delta 0), pack-reused 14371\u001b[K\n",
            "Receiving objects: 100% (14378/14378), 13.60 MiB | 4.59 MiB/s, done.\n",
            "Resolving deltas: 100% (9902/9902), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 6)) (7.9.0)\n",
            "Collecting ipython\n",
            "  Downloading ipython-8.7.0-py3-none-any.whl (761 kB)\n",
            "\u001b[K     |████████████████████████████████| 761 kB 49.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 7)) (3.2.2)\n",
            "Collecting matplotlib>=3.2.2\n",
            "  Downloading matplotlib-3.6.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.4 MB 66.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 8)) (1.21.6)\n",
            "Collecting numpy>=1.18.5\n",
            "  Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.1 MB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 9)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 10)) (7.1.2)\n",
            "Collecting Pillow>=7.1.2\n",
            "  Downloading Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 62.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 11)) (5.4.8)\n",
            "Collecting psutil\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 67.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 12)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 13)) (2.23.0)\n",
            "Collecting requests>=2.23.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 14)) (1.7.3)\n",
            "Collecting scipy>=1.4.1\n",
            "  Downloading scipy-1.9.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 33.8 MB 365 kB/s \n",
            "\u001b[?25hCollecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 16)) (1.12.1+cu113)\n",
            "Collecting torch>=1.7.0\n",
            "  Downloading torch-1.13.0-cp38-cp38-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[K     |██████████████████████████████  | 834.1 MB 1.2 MB/s eta 0:00:49tcmalloc: large alloc 1147494400 bytes == 0x3cec000 @  0x7ff5cbdba615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |████████████████████████████████| 890.2 MB 5.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 17)) (0.13.1+cu113)\n",
            "Collecting torchvision>=0.8.1\n",
            "  Downloading torchvision-0.14.0-cp38-cp38-manylinux1_x86_64.whl (24.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.3 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 18)) (4.64.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 22)) (2.9.1)\n",
            "Collecting tensorboard>=2.4.1\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 27)) (1.3.5)\n",
            "Collecting pandas>=1.1.4\n",
            "  Downloading pandas-1.5.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2 MB 63.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r yolov5/requirements.txt (line 28)) (0.11.2)\n",
            "Collecting seaborn>=0.11.0\n",
            "  Downloading seaborn-0.12.1-py3-none-any.whl (288 kB)\n",
            "\u001b[K     |████████████████████████████████| 288 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 7)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 7)) (21.3)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 7)) (3.0.9)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 68.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r yolov5/requirements.txt (line 7)) (0.11.0)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n",
            "\u001b[K     |████████████████████████████████| 295 kB 77.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 13)) (2022.9.24)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 13)) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 13)) (2.1.1)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 12 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 64.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 16)) (4.1.1)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 33 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->-r yolov5/requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.7.0->-r yolov5/requirements.txt (line 16)) (0.38.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (1.50.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (0.6.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (3.19.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 27)) (2022.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (5.2.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r yolov5/requirements.txt (line 22)) (3.2.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 64.5 MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit<3.1.0,>=3.0.11\n",
            "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
            "\u001b[K     |████████████████████████████████| 386 kB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->-r yolov5/requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->-r yolov5/requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->-r yolov5/requirements.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.8/dist-packages (from ipython->-r yolov5/requirements.txt (line 6)) (5.1.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.8/dist-packages (from ipython->-r yolov5/requirements.txt (line 6)) (4.8.0)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from ipython->-r yolov5/requirements.txt (line 6)) (2.6.1)\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.16->ipython->-r yolov5/requirements.txt (line 6)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect>4.3->ipython->-r yolov5/requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<3.1.0,>=3.0.11->ipython->-r yolov5/requirements.txt (line 6)) (0.2.5)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Installing collected packages: requests, nvidia-cublas-cu11, numpy, smmap, pure-eval, Pillow, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, fonttools, executing, contourpy, asttokens, torch, stack-data, prompt-toolkit, pandas, matplotlib-inline, matplotlib, jedi, gitdb, torchvision, thop, tensorboard, seaborn, scipy, psutil, ipython, gitpython\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: prompt-toolkit\n",
            "    Found existing installation: prompt-toolkit 2.0.10\n",
            "    Uninstalling prompt-toolkit-2.0.10:\n",
            "      Successfully uninstalled prompt-toolkit-2.0.10\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.11.2\n",
            "    Uninstalling seaborn-0.11.2:\n",
            "      Successfully uninstalled seaborn-0.11.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.9.0\n",
            "    Uninstalling ipython-7.9.0:\n",
            "      Successfully uninstalled ipython-7.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.11.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 8.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-9.3.0 asttokens-2.2.1 contourpy-1.0.6 executing-1.2.0 fonttools-4.38.0 gitdb-4.0.10 gitpython-3.1.29 ipython-8.7.0 jedi-0.18.2 matplotlib-3.6.2 matplotlib-inline-0.1.6 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 pandas-1.5.2 prompt-toolkit-3.0.36 psutil-5.9.4 pure-eval-0.2.2 requests-2.28.1 scipy-1.9.3 seaborn-0.12.1 smmap-5.0.0 stack-data-0.6.2 tensorboard-2.11.0 thop-0.1.1.post2209072238 torch-1.13.0 torchvision-0.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "prompt_toolkit",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 내 구글 드라이브로 이동\n",
        "#%cd \"/content/drive/MyDrive\"\n",
        "\n",
        "# Yolov5 github 레포지토리 clone\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "\n",
        "# 필요한 모듈 설치\n",
        "!pip install -U -r yolov5/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFY3htXRr5vM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d58ad70-da70-4972-f7f1-cd8839f1c930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch 1.13.0+cu117 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "#파이토치 버전 확인, cuda device properties 확인\n",
        "print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvMvoniR5Nys",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6a991f3-fc27-4693-cc99-09d915298b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-0.2.21-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 318 kB/s \n",
            "\u001b[?25hCollecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n",
            "Collecting urllib3==1.26.6\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 29.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.28.1)\n",
            "Collecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 67.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.6.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.23.5)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (9.3.0)\n",
            "Collecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n",
            "Collecting certifi==2021.5.30\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 62.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->roboflow) (21.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->roboflow) (1.0.6)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->roboflow) (4.38.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->roboflow) (2.1.1)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=b420ab3776ffa6376b06cffc1a579380fce433c5a2fd89b1cd065b4ff64c8e7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: urllib3, pyparsing, certifi, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.9.24\n",
            "    Uninstalling certifi-2022.9.24:\n",
            "      Successfully uninstalled certifi-2022.9.24\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 8.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-toolbelt-0.10.1 roboflow-0.2.21 urllib3-1.26.6 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in park_aug_aug_v7-2 to yolov5pytorch: 100% [296978384 / 296978384] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to park_aug_aug_v7-2 in yolov5pytorch:: 100%|██████████| 7582/7582 [00:03<00:00, 2437.16it/s]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"QcAdQ7dtBY0p29RfznGZ\")\n",
        "project = rf.workspace(\"new-workspace-29pun\").project(\"parking-occupancy-dataset-al6\")\n",
        "dataset = project.version(5).download(\"yolov5\")\"\"\"\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"QcAdQ7dtBY0p29RfznGZ\")\n",
        "project = rf.workspace(\"testpr3-2tk7v\").project(\"park_aug_aug_v7\")\n",
        "dataset = project.version(2).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/park_aug_aug_v7-2 /content/drive/MyDrive/data"
      ],
      "metadata": {
        "id": "E6SqXTv7EEP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/yolov5/ /content/drive/MyDrive/yolov5"
      ],
      "metadata": {
        "id": "sJPm8AlAt490"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdjiKSu958FJ"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "\n",
        "# 이미지 경로 list로 넣기 \n",
        "train_img_list = glob('/content/drive/MyDrive/data/train/images/*.jpg') + glob('/content/drive/MyDrive/data/train/images/*.jpeg')\n",
        "valid_img_list = glob('/content/drive/MyDrive/data/valid/images/*.jpg') + glob('/content/drive/MyDrive/data/valid/images/*.jpeg')\n",
        "mytrain_img_list=glob('/content/drive/MyDrive/train/image/*.jpg')+glob('/content/drive/MyDrive/train/image/*.jpeg')\n",
        "\n",
        "\n",
        "train_img_list += mytrain_img_list\n",
        "\n",
        "# txt 파일에 write\n",
        "with open('./train.txt', 'w') as f:\n",
        "\tf.write('\\n'.join(train_img_list) + '\\n')\n",
        "    \n",
        "with open('./valid.txt', 'w') as f:\n",
        "\tf.write('\\n'.join(valid_img_list) + '\\n')\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU2Z4OGl9H8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "730cfafe-06d1-418a-8972-45a025941603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"gitpython\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.29 smmap-5.0.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per ['gitpython']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=/content/drive/MyDrive/yolov5/models/yolov5x.yaml, data=/content/drive/MyDrive/data/data.yaml, hyp=drive/MyDrive/yolov5/data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=drive/MyDrive/yolov5/runs/train, name=result, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirements \"ipython\" \"thop>=0.1.1\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (7.9.0)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from thop>=0.1.1) (1.12.1+cu113)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->thop>=0.1.1) (4.1.1)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.2 thop-0.1.1.post2209072238\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per /content/drive/MyDrive/yolov5/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 v7.0-27-g454dae1 Python-3.8.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir drive/MyDrive/yolov5/runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 18.2MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt to yolov5x.pt...\n",
            "100% 166M/166M [00:03<00:00, 51.7MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     47103  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "YOLOv5x summary: 445 layers, 86224543 parameters, 86224543 gradients\n",
            "\n",
            "Transferred 738/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train... 3117 images, 0 backgrounds, 0 corrupt: 100% 3117/3117 [14:18<00:00,  3.63it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/valid... 482 images, 0 backgrounds, 0 corrupt: 100% 482/482 [04:02<00:00,  1.99it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/valid.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.68 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to drive/MyDrive/yolov5/runs/train/result3/labels.jpg... \n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mdrive/MyDrive/yolov5/runs/train/result3\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      4.71G    0.09425     0.1126    0.02145        261        320: 100% 195/195 [02:06<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:09<00:00,  1.62it/s]\n",
            "                   all        482       8332      0.359      0.279      0.243      0.074\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29      5.27G    0.07579     0.1041    0.01057        372        320: 100% 195/195 [02:02<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.05it/s]\n",
            "                   all        482       8332      0.339       0.41      0.266     0.0788\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29      5.27G     0.0713    0.09906   0.008718        219        320: 100% 195/195 [02:01<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.11it/s]\n",
            "                   all        482       8332      0.335      0.311      0.209     0.0432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29      5.27G    0.06785     0.0988    0.00799        384        320: 100% 195/195 [01:59<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.13it/s]\n",
            "                   all        482       8332      0.314      0.274      0.168     0.0344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29      5.27G     0.0653    0.09715   0.007284        386        320: 100% 195/195 [02:00<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:06<00:00,  2.31it/s]\n",
            "                   all        482       8332      0.503       0.41      0.349     0.0907\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29      5.27G    0.06326     0.0955   0.006839        372        320: 100% 195/195 [02:03<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.22it/s]\n",
            "                   all        482       8332      0.537       0.43      0.381     0.0994\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29      5.27G    0.06128    0.09314    0.00644        362        320: 100% 195/195 [02:03<00:00,  1.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.12it/s]\n",
            "                   all        482       8332      0.509      0.419      0.351     0.0914\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29      5.27G    0.06043    0.09178    0.00607        304        320: 100% 195/195 [02:05<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.14it/s]\n",
            "                   all        482       8332      0.509      0.438      0.359     0.0875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29      5.27G     0.0588     0.0895   0.005811        252        320: 100% 195/195 [02:07<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.14it/s]\n",
            "                   all        482       8332      0.563      0.473      0.434      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29      5.27G    0.05766    0.08882    0.00562        452        320: 100% 195/195 [02:10<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.23it/s]\n",
            "                   all        482       8332      0.565      0.427      0.389      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29      5.27G    0.05696    0.08671   0.005532        309        320: 100% 195/195 [02:01<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.26it/s]\n",
            "                   all        482       8332      0.573      0.503      0.446      0.124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29      5.27G    0.05585    0.08602   0.005235        353        320: 100% 195/195 [01:59<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.24it/s]\n",
            "                   all        482       8332      0.606      0.502      0.461      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29      5.27G     0.0548    0.08384   0.005094        409        320: 100% 195/195 [02:04<00:00,  1.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:06<00:00,  2.31it/s]\n",
            "                   all        482       8332      0.576      0.485      0.417      0.118\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29      5.27G    0.05385    0.08135   0.004917        301        320: 100% 195/195 [01:59<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.23it/s]\n",
            "                   all        482       8332      0.607       0.48      0.456      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29      5.27G    0.05349    0.08296   0.004897        409        320: 100% 195/195 [02:00<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:06<00:00,  2.29it/s]\n",
            "                   all        482       8332      0.583      0.473       0.43      0.121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29      5.27G    0.05269    0.08174   0.004723        403        320: 100% 195/195 [01:59<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.27it/s]\n",
            "                   all        482       8332      0.585      0.503      0.438      0.124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29      5.27G    0.05209    0.08007   0.004615        340        320: 100% 195/195 [02:00<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:06<00:00,  2.31it/s]\n",
            "                   all        482       8332      0.643      0.526      0.521      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29      5.27G    0.05143    0.07957   0.004547        349        320: 100% 195/195 [02:01<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.18it/s]\n",
            "                   all        482       8332      0.619      0.531      0.492      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29      5.27G    0.05089    0.07875    0.00456        228        320: 100% 195/195 [01:59<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:06<00:00,  2.33it/s]\n",
            "                   all        482       8332      0.597      0.503      0.455      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29      5.27G    0.05031    0.07781   0.004365        430        320: 100% 195/195 [02:04<00:00,  1.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.06it/s]\n",
            "                   all        482       8332      0.622      0.533      0.488      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29      5.27G    0.04976    0.07793   0.004362        412        320: 100% 195/195 [02:15<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.15it/s]\n",
            "                   all        482       8332        0.6      0.503      0.462      0.148\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29      5.27G    0.04893    0.07578   0.004228        444        320: 100% 195/195 [02:14<00:00,  1.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.04it/s]\n",
            "                   all        482       8332      0.606      0.505      0.458      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29      5.27G    0.04825    0.07469   0.004149        354        320: 100% 195/195 [02:14<00:00,  1.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.16it/s]\n",
            "                   all        482       8332      0.613      0.497      0.474      0.143\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29      5.27G    0.04795    0.07478   0.004206        416        320: 100% 195/195 [02:11<00:00,  1.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.15it/s]\n",
            "                   all        482       8332      0.603      0.502      0.468      0.148\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29      5.27G    0.04746    0.07427   0.004033        348        320: 100% 195/195 [02:06<00:00,  1.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.22it/s]\n",
            "                   all        482       8332      0.633      0.526      0.494      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29      5.27G    0.04692    0.07345   0.004045        309        320: 100% 195/195 [02:06<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.16it/s]\n",
            "                   all        482       8332      0.646       0.52      0.491      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29      5.27G     0.0463    0.07218   0.003928        205        320: 100% 195/195 [02:08<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.18it/s]\n",
            "                   all        482       8332      0.643       0.53      0.499      0.158\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29      5.27G    0.04588    0.07099   0.003883        355        320: 100% 195/195 [02:08<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.20it/s]\n",
            "                   all        482       8332      0.664      0.538      0.515      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29      5.27G    0.04582    0.07121   0.003902        275        320: 100% 195/195 [02:10<00:00,  1.49it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.23it/s]\n",
            "                   all        482       8332      0.615      0.526      0.479      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29      5.27G    0.04516    0.07002   0.003845        330        320: 100% 195/195 [02:07<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:07<00:00,  2.20it/s]\n",
            "                   all        482       8332      0.641      0.528      0.497      0.159\n",
            "\n",
            "30 epochs completed in 1.138 hours.\n",
            "Optimizer stripped from drive/MyDrive/yolov5/runs/train/result3/weights/last.pt, 173.0MB\n",
            "Optimizer stripped from drive/MyDrive/yolov5/runs/train/result3/weights/best.pt, 173.0MB\n",
            "\n",
            "Validating drive/MyDrive/yolov5/runs/train/result3/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5x summary: 322 layers, 86180143 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 16/16 [00:10<00:00,  1.49it/s]\n",
            "                   all        482       8332      0.664      0.537      0.515      0.172\n",
            "                     0        482       3495      0.589       0.35      0.347      0.106\n",
            "                     1        482       4837      0.739      0.723      0.684      0.239\n",
            "Results saved to \u001b[1mdrive/MyDrive/yolov5/runs/train/result3\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!python /content/drive/MyDrive/yolov5/train.py --img 320 --batch 16 --epochs 30 --data /content/drive/MyDrive/data/data.yaml --weights yolov5x.pt --name result --cfg /content/drive/MyDrive/yolov5/models/yolov5x.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uTp0gUkVDokN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8591e941-a1f8-4e4b-eda5-63926f869a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/yolov5/runs/train/result3/weights/best.pt'], source=/content/drive/MyDrive/주차장/Images/001_H.jpg, data=drive/MyDrive/yolov5/data/coco128.yaml, imgsz=[320, 320], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=drive/MyDrive/yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-27-g454dae1 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5x summary: 322 layers, 86180143 parameters, 0 gradients\n",
            "image 1/1 /content/drive/MyDrive/주차장/Images/001_H.jpg: 192x320 4 1s, 31.6ms\n",
            "Speed: 0.3ms pre-process, 31.6ms inference, 1.9ms NMS per image at shape (1, 3, 320, 320)\n",
            "Results saved to \u001b[1mdrive/MyDrive/yolov5/runs/detect/exp\u001b[0m\n",
            "/content/drive/MyDrive/주차장/Images/001_H.jpg\n",
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/yolov5/runs/train/result3/weights/best.pt'], source=/content/drive/MyDrive/주차장/Images/001_G2.jpg, data=drive/MyDrive/yolov5/data/coco128.yaml, imgsz=[320, 320], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=drive/MyDrive/yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-27-g454dae1 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5x summary: 322 layers, 86180143 parameters, 0 gradients\n",
            "image 1/1 /content/drive/MyDrive/주차장/Images/001_G2.jpg: 128x320 5 1s, 27.4ms\n",
            "Speed: 0.3ms pre-process, 27.4ms inference, 1.5ms NMS per image at shape (1, 3, 320, 320)\n",
            "Results saved to \u001b[1mdrive/MyDrive/yolov5/runs/detect/exp2\u001b[0m\n",
            "/content/drive/MyDrive/주차장/Images/001_G2.jpg\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "# 이미지 경로 list로 넣기 \n",
        "#test_img_list = glob('/content/drive/MyDrive/CCTV/*.jpg')\n",
        "test_img = glob('/content/drive/MyDrive/주차장/Images/*.jpg')+glob('/content/drive/MyDrive/주차장/Images/*.jpeg')\n",
        "\n",
        "#source : 테스트 이미지(혹은 폴더)경로\n",
        "#weights: 학습이 완료된 weight 파일 경로(pt형식)\n",
        "#conf: conf_threshold값 (0~1사이값)\n",
        "#class score가 설정한 값을 넘겨야 바운딩 박스를 그린다.\n",
        "#for test_name in test_img_list:\n",
        "#  !python /content/yolov5/detect.py --source {test_name} --weights /content/drive/MyDrive/models/result3/weights/best.pt --img 320 --conf 0.5\n",
        "\n",
        "#TODO: 라운딩 박스 좌표값 추출\n",
        "for test_imt in test_img:\n",
        "  !python /content/drive/MyDrive/yolov5/detect.py --weights /content/drive/MyDrive/yolov5/runs/train/result3/weights/best.pt --img 320 --conf 0.5 --source {test_imt}\n",
        "  print(test_imt)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, shutil\n",
        "#테스트 파일 전체 삭제\n",
        "\n",
        "dir = '/content/drive/MyDrive/yolov5/runs/detect/'\n",
        "filelist = glob.glob(os.path.join(dir,\"*\"))\n",
        "for f in filelist:\n",
        "  shutil.rmtree(f)"
      ],
      "metadata": {
        "id": "e2osPTMMXcoc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shutil.rmtree('/content/drive/MyDrive/data/')"
      ],
      "metadata": {
        "id": "qHDsuT8Nyj4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os, glob, shutil\n",
        "#테스트 파일 전체 삭제\n",
        "\n",
        "#dir = '/content/drive/MyDrive/data'\n",
        "#filelist = glob.glob(os.path.join(dir,\"*\"))\n",
        "#for f in filelist:\n",
        "#  os.remove(f)"
      ],
      "metadata": {
        "id": "8VSerMSuFMcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "최종이미지 : res_Image.jpg\n",
        "(나머지 나오는 jpg, txt파일들은 무시해도 무관함)\n",
        "\n",
        "필요한 셋업 파일 및 정보\n",
        "\n",
        "1. empty/label에 디텍팅 박스 좌표 정보(좌에서 우순으로 수정함)\n",
        "\n",
        "2. parking.txt : 주차장 모습을 텍스트로 표현\n",
        "\n",
        "3. parkingArea.txt : cctv순서대로 담당하고 있는 주차 구역에 대한 좌표 정보\n",
        "\n",
        "4. cntPP : 코드 안에서 cctv마다 담당하고 있는 주차 구역의 수를 알려주는 배열\n",
        "\n"
      ],
      "metadata": {
        "id": "M5A07xPa-O4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass \n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "import csv\n",
        "import time\n",
        "import numpy as np\n",
        "from queue import Queue"
      ],
      "metadata": {
        "id": "U5L3OI5p-RU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DOT:\n",
        "  row: int = None\n",
        "  col: int = None\n",
        "  number: int = None\n",
        "\n",
        "\n",
        "map = [['z' for col in range(1001)] for row in range(1001)]\n",
        "tmp_map = [['z' for col in range(1001)] for row in range(1001)]\n",
        "parking_map = [[[\"z\" for idx1 in range(1001)] for idx2 in range(1001)] for idx3 in range(100)]\n",
        "comment = [\"none\" for idx in range(1001)]\n",
        "rowSize = 0; colSize = 0;\n",
        "i = 0; j = 0;\n",
        "#입구 위치\n",
        "startX = 0; startY = 0;\n",
        "#주차 공간 정보\n",
        "parkingPlace = [DOT() for idx in range(1001)]\n",
        "road = [list() for idx in range(1001)]\n",
        "emptyFlag = ['z' for i in range(1001)] # \"a\"면 빈칸 \"A\"면 차있는 칸\n",
        "direction = ['z' for i in range(1001)]\n",
        "numOfPP = 0\n",
        "ppIdx = 0\n",
        "dx = [1,-1,0,0]\n",
        "dy = [0,0,1,-1]\n",
        "\n",
        "visit = [[0 for col in range(1001)]for row in range(1001)]\n",
        "\n",
        "#초기 디텍팅박스 좌표 정보\n",
        "initialBox = []\n",
        "mappingBox = []\n",
        "\n",
        "#cctv 담당 구역 개수(초기 정보)\n",
        "cntPP  = [4,4,4,4,4,4,5,4,5,4]\n"
      ],
      "metadata": {
        "id": "7kdeAdnO-VQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 빈공간 좌표 정보 넣는 함수"
      ],
      "metadata": {
        "id": "3pQOD8UFT-YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initBox():\n",
        "  #수정\n",
        "  for i in range(10):\n",
        "    f = open(\"/content/drive/MyDrive/empty/labels/001_\" + chr(ord(\"A\") + i)+\".txt\", 'r')\n",
        "    tmpList = []\n",
        "    while True:\n",
        "      line = f.readline()\n",
        "\n",
        "      if not line:break\n",
        "\n",
        "      e,a,b,c,d = line.split()\n",
        "\n",
        "      e=int(e)\n",
        "      a=float(a)\n",
        "      b=float(b)\n",
        "      c=float(c)\n",
        "      d=float(d)\n",
        "\n",
        "      tmpList.append(e)\n",
        "      tmpList.append(a)\n",
        "      tmpList.append(b)\n",
        "      tmpList.append(c)\n",
        "      tmpList.append(d)\n",
        "    \n",
        "    initialBox.append(tmpList)\n",
        "\n",
        "  f = open(\"/content/drive/MyDrive/parkingArea.txt\", 'r')\n",
        "  \n",
        "  while True:\n",
        "    line = f.readline()\n",
        "\n",
        "    if not line:break\n",
        "\n",
        "    x = line.split()\n",
        "\n",
        "    for i in range(1, len(x)):\n",
        "      x[i] = int(x[i])\n",
        "\n",
        "    mappingBox.append(x)\n",
        "\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "94FzBP23T93S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## parking.txt 구축"
      ],
      "metadata": {
        "id": "2KdWQdbmjSfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeTXT():\n",
        "  #elem => A구역부터 차량 여부(1, 0)와 디텍팅 박스 좌표 정보\n",
        "  #mappingBox를 통해 (방향, 좌표1, 좌표2....) 차량 여부를 써줘야함.\n",
        "  idx = 0\n",
        "  for elem in initialBox:\n",
        "    mapIdx = 1\n",
        "    for i in range(0, len(elem), 5):\n",
        "      if elem[i] == 1:\n",
        "        #제대로 된 mapIdx 찾아주기\n",
        "        #cctv가 4대의 주차구역을 담당\n",
        "        calList = []\n",
        "\n",
        "        if cntPP[idx] == 4:\n",
        "          for j in range(1,5):\n",
        "            calList.append(abs(0.1*j*2-elem[i+1]))\n",
        "   \n",
        "        #cctv가 5대의 주차구역을 담당\n",
        "        elif cntPP[idx] == 5:\n",
        "          for j in range(1,10,2):\n",
        "            calList.append(abs(0.1*j-elem[i+1]))\n",
        "\n",
        "        mapIdx = calList.index(min(calList))\n",
        "        mapIdx = mapIdx*2+1\n",
        "\n",
        "        x = mapIdx\n",
        "        y = mapIdx+1\n",
        "        map[mappingBox[idx][x]][mappingBox[idx][y]] = \"A\"\n",
        "\n",
        "        if mappingBox[idx][0] == \"d\":\n",
        "          map[mappingBox[idx][x]+1][mappingBox[idx][y]] = \"A\"\n",
        "          map[mappingBox[idx][x]+2][mappingBox[idx][y]] = \"A\"\n",
        "        elif mappingBox[idx][0] == \"l\":\n",
        "          map[mappingBox[idx][x]][mappingBox[idx][y]-1] = \"A\"\n",
        "          map[mappingBox[idx][x]][mappingBox[idx][y]-2] = \"A\"\n",
        "      \n",
        "      #mapIdx += 2\n",
        "\n",
        "      #elif elem[i] == 0:\n",
        "\n",
        "\n",
        "    idx += 1\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "040528y0jSZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 가는 길 만드는 함수"
      ],
      "metadata": {
        "id": "Bw8KBmwqBonk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def searchRoad(idx, x, y, cost):\n",
        "  road[idx].append(DOT(row = x, col = y, number = -1))\n",
        "  while(True):\n",
        "    for k in range(4):\n",
        "      nx = x + dx[k]\n",
        "      ny = y + dy[k]\n",
        "\n",
        "      if nx < 0 or ny < 0 or nx > rowSize or ny > colSize : continue\n",
        "      if visit[nx][ny] == cost-1:\n",
        "        road[idx].append(DOT(row = nx, col = ny, number = -1))\n",
        "        x = nx\n",
        "        y = ny\n",
        "        cost  -= 1\n",
        "        break\n",
        "    \n",
        "    if cost <= 1 : break\n"
      ],
      "metadata": {
        "id": "I7cg36dbAGeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## bfs"
      ],
      "metadata": {
        "id": "g264hnOEBt5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def bfs(num):\n",
        "  for i in range(rowSize+1):\n",
        "    for j in range(colSize+1):\n",
        "      tmp_map[i][j] = map[i][j]\n",
        "      visit[i][j] = 0\n",
        "\n",
        "  #q = list()\n",
        "  q = Queue()\n",
        "  #q.append((startX, startY, 1))\n",
        "  q.put((startX, startY, 1))\n",
        "\n",
        "  visit[startX][startY] = 1\n",
        "\n",
        "  dirIdx = 0\n",
        "\n",
        "  while q.empty() == False:\n",
        "    tmp = q.get()\n",
        "    x = tmp[0]\n",
        "    y = tmp[1]\n",
        "    cost = tmp[2]\n",
        "\n",
        "    for k in range(4):\n",
        "      nx = x + dx[k]\n",
        "      ny = y + dy[k]\n",
        "\n",
        "      if (nx < 0) or (ny < 0) or (nx > rowSize) or (ny > colSize) : continue\n",
        "      if (tmp_map[nx][ny] == 'd') or (tmp_map[nx][ny] == 'e') or (tmp_map[nx][ny] == 'f') or (tmp_map[nx][ny] == 'z') : continue\n",
        "      if visit[nx][ny] >= 1 : continue\n",
        "\n",
        "      visit[nx][ny] = cost + 1\n",
        "      q.put((nx,ny,cost+1))\n",
        "\n",
        "      if tmp_map[nx][ny] == 'a' or tmp_map[nx][ny] == 'A':\n",
        "        for t in range(1001):\n",
        "          if parkingPlace[t].row == None:\n",
        "            parkingPlace[t].row = nx\n",
        "            parkingPlace[t].col = ny\n",
        "            #parkingPlace[ppIdx].number = ppIdx\n",
        "            parkingPlace[t].number = t\n",
        "            emptyFlag[t] = tmp_map[nx][ny]\n",
        "            dirIdx = t\n",
        "            break\n",
        "\n",
        "        #searchRoad(ppIdx, nx, ny, cost+1)\n",
        "        searchRoad(t, nx, ny, cost+1)\n",
        "\n",
        "        map[nx][ny] = 'f'\n",
        "\n",
        "        for l in range(4):\n",
        "          px = nx + dx[l]\n",
        "          py = ny + dy[l]\n",
        "\n",
        "          if px < 0 or py < 0 or px > rowSize or py > colSize : continue\n",
        "\n",
        "          if tmp_map[px][py] == 'a' or tmp_map[px][py] == 'A':\n",
        "            if l == 0:\n",
        "              direction[dirIdx] = 'd'\n",
        "            elif l == 1:\n",
        "              direction[dirIdx] = 'u'\n",
        "            elif l == 2:\n",
        "              direction[dirIdx] = 'r'\n",
        "            elif l == 3:\n",
        "              direction[dirIdx] = 'l'\n",
        "            map[px][py] = 'f'\n",
        "            map[px+dx[l]][py+dy[l]] = 'f'\n",
        "\n",
        "            break\n",
        "      \n",
        "        #q.clear()\n",
        "        return\n"
      ],
      "metadata": {
        "id": "fyFp9PihBm2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 주차장 평면도 출력"
      ],
      "metadata": {
        "id": "dqjvI-ZSFkgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printMap(m):\n",
        "  for i in range(rowSize+1):\n",
        "    for j in range(colSize+1):\n",
        "      print(m[i][j], end = \"\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "R08lUL17FNjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 주차 공간의 정보(행 위치, 열 위치, 우선순위 번호)를 출력"
      ],
      "metadata": {
        "id": "t7h83GkKFnLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printParkingPlace():\n",
        "  for i in range(numOfPP):\n",
        "    print(parkingPlace[i].row, parkingPlace[i].col, parkingPlace[i].number, emptyFlag[i])"
      ],
      "metadata": {
        "id": "jao38GjhFXts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##주차 공간 까지 가는 길을 칸 하나하나 보여줌"
      ],
      "metadata": {
        "id": "U_4DtZOxFsO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printRoad(idx):\n",
        "  print(\"parkingPlace :\", parkingPlace[idx].row, parkingPlace[idx].col)\n",
        "  \n",
        "  for i in range(len(road[idx])):\n",
        "    print(road[idx][i][0], road[idx][i][1])"
      ],
      "metadata": {
        "id": "hKdzpjGGFuLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeTXTRoad(idx):\n",
        "  f = open(\"road.txt\", \"w\")\n",
        "\n",
        "  tmpStr = \"parkingPlace :\" + str(parkingPlace[idx].row) + \" \" + str(parkingPlace[idx].col) + \"\\n\"\n",
        "  f.write(tmpStr)\n",
        "  \n",
        "  for i in range(len(road[idx])):\n",
        "    tmpStr = str(road[idx][i].row) + \" \" + str(road[idx][i].col) + \"\\n\"\n",
        "    f.write(tmpStr)\n",
        "\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "PuliJMQnQhcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 주차 공간까지 가는데에 필요한 정보(네비게이션)을 구축"
      ],
      "metadata": {
        "id": "c5mhKHtiJPtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeComment():\n",
        "  for idx in range(numOfPP):\n",
        "    dIdx = 3\n",
        "    nx = startX + dx[dIdx]\n",
        "    ny = startY + dy[dIdx]\n",
        "    num = 2\n",
        "    flag = 0\n",
        "    tmp_com = \"\"\n",
        "\n",
        "    while parking_map[idx][nx][ny] != 'U':\n",
        "      #print(parking_map[idx][nx][ny])\n",
        "      if parking_map[idx][nx + dx[dIdx]][ny + dy[dIdx]] == 'P' : num += 2\n",
        "      else:\n",
        "        tmp_com += \"전방으로 약\" + str(num) + \"미터 직진 후 \"\n",
        "        num = 2\n",
        "\n",
        "        for k in range(4):\n",
        "          cx = nx + dx[k]\n",
        "          cy = ny + dy[k]\n",
        "\n",
        "          if cx < 0 or cy < 0 or cx > rowSize or cy > colSize : continue\n",
        "          if parking_map[idx][cx][cy] == 'U' :\n",
        "            tmp_com += \"\\n주차 공간 도착입니다. \\n\"\n",
        "            comment[idx] = tmp_com\n",
        "            flag = 1\n",
        "            break\n",
        "        \n",
        "\n",
        "        if flag == 0:\n",
        "          if dIdx == 3:\n",
        "            if parking_map[idx][nx+dx[0]][ny+dy[0]] == 'P':\n",
        "              dIdx = 0; tmp_com += \"좌회전 입니다. \\n이어서 \"\n",
        "            elif parking_map[idx][nx+dx[1]][ny + dy[1]] == 'P':\n",
        "              dIdx = 1; tmp_com += \"우회전 입니다. \\n이어서 \"\n",
        "          elif dIdx == 2:\n",
        "            if parking_map[idx][nx+dx[0]][ny+dy[0]] == 'P':\n",
        "              dIdx = 0; tmp_com += \"우회전 입니다. \\n이어서 \"\n",
        "            elif parking_map[idx][nx+dx[1]][ny + dy[1]] == 'P':\n",
        "              dIdx = 1; tmp_com += \"좌회전 입니다. \\n이어서 \"\n",
        "          elif dIdx == 1:\n",
        "            if parking_map[idx][nx+dx[2]][ny+dy[2]] == 'P':\n",
        "              dIdx = 2; tmp_com += \"좌회전 입니다. \\n이어서 \"\n",
        "            elif parking_map[idx][nx+dx[3]][ny + dy[3]] == 'P':\n",
        "              dIdx = 3; tmp_com += \"우회전 입니다. \\n이어서 \"\n",
        "          elif dIdx == 0:\n",
        "            if parking_map[idx][nx+dx[2]][ny+dy[2]] == 'P':\n",
        "              dIdx = 2; tmp_com += \"우회전 입니다. \\n이어서 \"\n",
        "            elif parking_map[idx][nx+dx[3]][ny + dy[3]] == 'P':\n",
        "              dIdx = 3; tmp_com += \"좌회전 입니다. \\n이어서 \"\n",
        "        else : break\n",
        "      nx = nx + dx[dIdx]; ny = ny + dy[dIdx]\n",
        "    "
      ],
      "metadata": {
        "id": "PuaD3_nKJUth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 가는 길이 표시된 맵을 구축"
      ],
      "metadata": {
        "id": "fzaDkeOCLaFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeRoadMap():\n",
        "  for idx in range(numOfPP):\n",
        "    one = parkingPlace[idx]\n",
        "    map[one.row][one.col] = 'U'\n",
        "\n",
        "    for k in range(4):\n",
        "      nx = one.row + dx[k]\n",
        "      ny = one.col + dy[k]\n",
        "\n",
        "      if nx < 0 or ny < 0 or nx > rowSize or ny > colSize : continue\n",
        "      if map[nx][ny] == 'f':\n",
        "        two = DOT(row = nx, col = ny, number = -1)\n",
        "        three = DOT(row = nx + dx[k], col = ny + dy[k], number = -1)\n",
        "    \n",
        "    map[two.row][two.col] = 'U'\n",
        "    map[three.row][three.col] = 'U'\n",
        "\n",
        "    for k in range(1, len(road[idx])-1):\n",
        "      map[road[idx][k].row][road[idx][k].col] = 'P'\n",
        "    \n",
        "    for i in range(rowSize+1):\n",
        "      for j in range(colSize+1):\n",
        "        parking_map[idx][i][j] = map[i][j]\n",
        "    \n",
        "    for k in range(1, len(road[idx]) - 1):\n",
        "      map[road[idx][k].row][road[idx][k].col]  = '0'\n",
        "\n",
        "    map[one.row][one.col] = 'f'\n",
        "    map[two.row][two.col] = 'f'\n",
        "    map[three.row][three.col] = 'f'"
      ],
      "metadata": {
        "id": "gSPQCdX9Lb4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 메인"
      ],
      "metadata": {
        "id": "Euv4su2aPeDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount = True)\n",
        "\n",
        "#모두 비어있을 때의 좌표 구축\n",
        "initBox()\n",
        "\n",
        "f = open(\"/content/drive/MyDrive/parking.txt\", 'r', encoding = 'cp949')\n",
        "\n",
        "for i in range(1000):\n",
        "  for j in range(1000):\n",
        "    map[i][j] = 'z'\n",
        "\n",
        "i = 0; j = 0\n",
        "\n",
        "numOfPP = int(f.readline())\n",
        "\n",
        "c = f.read()\n",
        "\n",
        "for k in range(len(c)):\n",
        "  if c[k] == '\\n':\n",
        "    j = 0; i+=1; continue\n",
        "  \n",
        "  if c[k] == 'c':\n",
        "    startX = i; startY = j\n",
        "\n",
        "  map[i][j] = c[k]\n",
        "  j += 1\n",
        "\n",
        "  rowSize = max(i, rowSize)\n",
        "  colSize = max(j, colSize)\n",
        "\n",
        "#주차공간마다 차량 여부 맵핑\n",
        "makeTXT()\n",
        "\n",
        "for n in range(numOfPP):\n",
        "  bfs(n)\n",
        "\n",
        "makeRoadMap();\n",
        "makeComment();\n",
        "\n",
        "wfp = open(\"parkingPlace.txt\", \"w\")\n",
        "\n",
        "for i in range(numOfPP):\n",
        "    tmpStr = str(parkingPlace[i].row) + \" \" + str(parkingPlace[i].col) + \" \" + str(parkingPlace[i].number) + \" \" + str(emptyFlag[i]) + \" \" + direction[i] + \"\\n\"\n",
        "    wfp.write(tmpStr)\n",
        "\n",
        "fcom = open(\"comment.txt\", \"w\")\n",
        "\n",
        "for i in range(numOfPP):\n",
        "  if emptyFlag[i] == 'a':\n",
        "    makeTXTRoad(i)\n",
        "    fcom.write(comment[i])\n",
        "    break\n",
        "\n",
        "\n",
        "fcom.close()\n",
        "f.close()\n",
        "wfp.close()"
      ],
      "metadata": {
        "id": "mq25p8W3Pfu1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7d449a-8833-4a91-e6a0-23fccef5e6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이미지 만들기"
      ],
      "metadata": {
        "id": "DsJbeGZj9GUi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RGB : (106,157,255)"
      ],
      "metadata": {
        "id": "T3BgdgDH_piD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class dot:\n",
        "  row: int = None\n",
        "  col: int = None\n",
        "  number: int = None\n",
        "  flag: int = None #이미 주차되어 있는지 여부\n",
        "  direc : str = None\n",
        "\n",
        "fp = open(\"parkingPlace.txt\", \"r\")\n",
        "fp2 = open(\"road.txt\", \"r\")\n",
        "\n",
        "line = fp2.readline()\n",
        "line = line[14:]\n",
        "a, b = line.split()\n",
        "a = int(a); b= int(b)\n",
        "\n",
        "parkingMap = [dot() for i in range(int(1001))]\n",
        "\n",
        "idx = 0\n",
        "\n",
        "while True:\n",
        "    line = fp.readline()\n",
        "    if not line: break\n",
        "    row, col, number, flag, direc = line.split()\n",
        "    parkingMap[idx].row = int(row)\n",
        "    parkingMap[idx].col = int(col)\n",
        "    parkingMap[idx].number = int(number)\n",
        "    parkingMap[idx].direc = direc\n",
        "    if flag == \"A\":\n",
        "        parkingMap[idx].flag = 1\n",
        "    elif flag == 'a':\n",
        "        parkingMap[idx].flag = 0\n",
        "    idx+=1\n",
        "\n",
        "#txt파일에서 주차 공간 중 a로 되어 있는 곳은 빈 주차 공간, A로 되어 있는 곳은 주차가 이미 되어 있는 공간\n",
        "\n",
        "img = np.full((1500,1500,3), 255, np.uint8)\n",
        "\n",
        "#주차장 라인\n",
        "cv2.line(img, (320, 150), (320, 415), (170,170,170), 7)\n",
        "\n",
        "cv2.line(img, (110, 110), (95, 110), (200,200,200), 3)\n",
        "cv2.arrowedLine(img, (95,110), (95,130), (200,200,200), 3, tipLength = 0.5)\n",
        "\n",
        "cv2.line(img, (95, 445), (95, 460), (200,200,200), 3)\n",
        "cv2.arrowedLine(img, (95,460), (115,460), (200,200,200), 3, tipLength = 0.5)\n",
        "\n",
        "cv2.line(img, (260, 460), (280, 460), (200,200,200), 3)\n",
        "cv2.arrowedLine(img, (280,460), (280,440), (200,200,200), 3, tipLength = 0.5)\n",
        "cv2.arrowedLine(img, (280,460), (300,460), (200,200,200), 3, tipLength = 0.5)\n",
        "\n",
        "cv2.line(img, (300, 110), (280, 110), (200,200,200), 3)\n",
        "cv2.arrowedLine(img, (280,110), (280,130), (200,200,200), 3, tipLength = 0.5)\n",
        "cv2.arrowedLine(img, (280,110), (260,110), (200,200,200), 3, tipLength = 0.5)\n",
        "\n",
        "\n",
        "#주차장 그리기\n",
        "for i in range(1001):\n",
        "    if a == parkingMap[i].row and b == parkingMap[i].col:\n",
        "        color = (203, 199, 255)\n",
        "        colorFlag = -1\n",
        "    else:\n",
        "        if parkingMap[i].flag == 1:\n",
        "            color = (255,157,106)\n",
        "            colorFlag = -1\n",
        "        else:\n",
        "            color = (255,157,106)\n",
        "            colorFlag = 2\n",
        "\n",
        "    if parkingMap[i].row == None: break\n",
        "    else:\n",
        "        if parkingMap[i].direc == \"u\":\n",
        "            cv2.rectangle(img, (\n",
        "            parkingMap[i].col * 15+10,\n",
        "                parkingMap[i].row * 15),(parkingMap[i].col*15 + 30,parkingMap[i].row*15 + 30),\n",
        "                          color, colorFlag)\n",
        "\n",
        "        elif parkingMap[i].direc == \"d\":\n",
        "            cv2.rectangle(img, (\n",
        "            parkingMap[i].col * 15+10,\n",
        "                parkingMap[i].row * 15+25), (parkingMap[i].col*15 + 30, parkingMap[i].row*15 + 55),\n",
        "                          color, colorFlag)\n",
        "\n",
        "        elif parkingMap[i].direc == \"l\":\n",
        "            cv2.rectangle(img, (\n",
        "            parkingMap[i].col * 15+20,\n",
        "                parkingMap[i].row * 15+20), (parkingMap[i].col*15 - 10, parkingMap[i].row*15 + 40),\n",
        "                          color, colorFlag)\n",
        "        \n",
        "        elif parkingMap[i].direc == \"r\":\n",
        "            cv2.rectangle(img, (\n",
        "            parkingMap[i].col * 15+20,\n",
        "                parkingMap[i].row * 15+40), (parkingMap[i].col*15 +50, parkingMap[i].row*15 +20),\n",
        "                          color, colorFlag)\n",
        "\n",
        "for i in range(1001):\n",
        "    if a == parkingMap[i].row and b == parkingMap[i].col:\n",
        "        ch = parkingMap[i].direc\n",
        "        break\n",
        "\n",
        "roadList = []\n",
        "\n",
        "while True:\n",
        "    line = fp2.readline()\n",
        "\n",
        "    if not line: break\n",
        "\n",
        "    a,b = line.split()\n",
        "    a = int(a); b = int(b)\n",
        "\n",
        "    roadList.append((a,b))\n",
        "\n",
        "roadList.reverse()\n",
        "\n",
        "if ch == 'd':\n",
        "    del roadList[len(roadList)-1]\n",
        "\n",
        "for i in range(len(roadList)-1):\n",
        "    a, b = roadList[i]\n",
        "    c, d = roadList[i+1]\n",
        "    if ch == 'u':\n",
        "        if i == len(roadList)-2:\n",
        "            cv2.arrowedLine(img, (b * 15 + 5+15, a * 15 + 30), (d * 15 + 5+15, c * 15 + 30), (0, 0, 255), 3, tipLength = 0.5)\n",
        "        else:\n",
        "            cv2.line(img, (b*15+5+15,a*15+30), (d*15+5+15,c*15+30), (0,0,255), 3)\n",
        "    elif ch == 'l':\n",
        "        if i == len(roadList)-2:\n",
        "            cv2.arrowedLine(img, (b * 15 + 5+15, a * 15 + 5+25), (d * 15 + 5+15, c * 15 + 5+25), (0, 0, 255), 3, tipLength = 0.5)\n",
        "        else:\n",
        "            cv2.line(img, (b*15+5+15,a*15+5+25), (d*15+5+15,c*15+5+25), (0,0,255), 3)\n",
        "    elif ch == 'r':\n",
        "        if i == len(roadList)-2:\n",
        "            cv2.arrowedLine(img, (b * 15 + 5+10, a * 15 + 5+25), (d * 15 + 5+10, c * 15 + 5+25), (0, 0, 255), 3, tipLength = 0.5)\n",
        "        else:\n",
        "            cv2.line(img, (b * 15+5+10, a * 15 + 5+25), (d * 15 + 5+10, c * 15 + 5+25), (0, 0, 255), 3)\n",
        "    elif ch == 'd':\n",
        "        if i == len(roadList)-2:\n",
        "            cv2.arrowedLine(img, (b * 15 + 5 + 15, a * 15 + 20 + 15), (d * 15 + 5 + 15, c * 15 + 20+15), (0, 0, 255), 3, tipLength = 0.5)\n",
        "        else:\n",
        "            cv2.line(img, (b*15+5 + 15, a*15+20+15), (d*15+5 + 15, c*15+20+15), (0,0,255), 3)\n",
        "\n",
        "cv2.line(img, (10, 550), (320, 550), (255,157,106), 3)\n",
        "\n",
        "\n",
        "cv2_imshow(img)\n",
        "cv2.imwrite(\"Image.jpg\", img)\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "fp.close()\n",
        "fp2.close()"
      ],
      "metadata": {
        "id": "-W9NyvLMif3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "019ae799-ab4b-4e8b-d3fe-422ed1e908e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=1500x1500 at 0x7F4CF22D7D30>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 네비게이션 사진에 텍스트 붙이기\n"
      ],
      "metadata": {
        "id": "xDCZNtSF8NoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageDraw\n",
        "\n",
        "fontsize = 16\n",
        "fnt = ImageFont.truetype(\"/content/drive/MyDrive/NanumGothic.ttf\", fontsize)\n",
        "img = Image.open(\"/content/Image.jpg\")\n",
        "draw = ImageDraw.Draw(img)\n",
        "\n",
        "# 텍스트 위치 설정을 위해 이미지 사이즈를 도출합니다.\n",
        "w, h = img.size\n",
        "\n",
        "txt_file = open(\"comment.txt\", \"r\")\n",
        "text = txt_file.read()\n",
        "txt_file.close()\n",
        "\n",
        "#text = \"샘플 글자\"\n",
        "\n",
        "w_txt, h_txt = draw.textsize(text, fnt)\n",
        "\n",
        "margin = 500\n",
        "x = w - w_txt - 1200\n",
        "y = h - h_txt - 850\n",
        "draw.text((x,y), text, fill = 'black', font = fnt)\n",
        "\n",
        "img.show()\n",
        "img.save(\"res_Image.jpg\")\n",
        "\n",
        "saveImg = cv2.imread(\"res_Image.jpg\")\n",
        "\n",
        "saveImg = saveImg[0:660, 0:330]\n",
        "\n",
        "cv2.imwrite(\"/content/drive/MyDrive/res_Image.jpg\", saveImg)\n",
        "\n",
        "#cv2.imwrite(\"/content/drive/MyDrive/res_Image.jpg\",)"
      ],
      "metadata": {
        "id": "Tb2UBiPA8M62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d42a06c-eea7-4eb4-b961-cc6a3e62bb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}